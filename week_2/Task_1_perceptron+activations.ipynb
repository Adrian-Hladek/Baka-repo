{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "rqzWxgjcE3yB"
      },
      "source": [
        "# In Today's task you will\n",
        "\n",
        "- Implement Linear (also called Dense, Fully-Connected) layer as a Perceptron.\n",
        "- Allow your solution to stack multiple layers to form MLP network.\n",
        "- Perform forward propagation through your network.\n",
        "\n",
        "This (and later) template implementation is similar to Pytorch framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "xVDwjg0GE3yC"
      },
      "source": [
        "## Task 1a:\n",
        "\n",
        "Declare a siMple perceptron (Linear layer) that inherits defined class Module - it is here, to help you store all network layers.\n",
        "\n",
        "The simple perceptron should be constructed of:\n",
        "1. Input features\n",
        "2. Followed by 1 Linear Layer with \"single neuron\"\n",
        "3. Activation function\n",
        "\n",
        "\n",
        "4. Perform forward pass for the example feature vectors `xInput1` and `xInput2` of `size = 10` features.\n",
        "Use prepared plot to view the results. (Repeat the process using all 4 activation functions.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "N_IVsuyqE3yC"
      },
      "outputs": [],
      "source": [
        "# Import\n",
        "import numpy as np\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "from collections import OrderedDict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "5S9M5Zv7E3yC"
      },
      "source": [
        "### Module\n",
        "\n",
        "All deep learning frameworks have usually one elementary building block.\n",
        "In our project, we follow the structure of the pytorch, so the elementary building block is called **`Module`**.\n",
        "Now, it is pretty simple, but it will get more complex and more useful...\n",
        "You can see function `.backward` that will later contain the partial derivations of chain rule for backward pass and parameter optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "upGrPYH8E3yD"
      },
      "outputs": [],
      "source": [
        "class Module:\n",
        "    def __init__(self):\n",
        "        self.modules = OrderedDict()\n",
        "\n",
        "    def add_module(self, module, name:str):\n",
        "        if hasattr(self, name) and name not in self.modules:\n",
        "            raise KeyError(\"attribute '{}' already exists\".format(name))\n",
        "        elif '.' in name:\n",
        "            raise KeyError(\"module name can't contain \\\".\\\"\")\n",
        "        elif name == '':\n",
        "            raise KeyError(\"module name can't be empty string \\\"\\\"\")\n",
        "        self.modules[name] = module\n",
        "\n",
        "    def forward(self, *args, **kwargs) -> np.ndarray:\n",
        "        pass\n",
        "\n",
        "    def backward(self, *args, **kwargs):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.forward(*args, **kwargs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "Kuoabo1cE3yD"
      },
      "source": [
        "## Linear Layer\n",
        "\n",
        "In the lecture, we talked about a Perceptron and Single Layer Perceptron as an object with weight for every input value.\n",
        "In the frameworks, the \"Fully connected layer\" is implemented in Matrix Algebra.\n",
        "\n",
        "Also, the activation function and layer logic are separated for easier backward propagation (chain rule) and optimization (The topic of 2nd+3rd lecture).\n",
        "\n",
        "(If you want to know more, you can go to the lecture, or you can take a look on the implementation of forward and backward propagation on your own.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "H4NMZ5TnE3yD"
      },
      "outputs": [],
      "source": [
        "#------------------------------------------------------------------------------\n",
        "#   Linear class\n",
        "#------------------------------------------------------------------------------\n",
        "class Linear(Module):\n",
        "    def __init__(self, in_features, out_features):\n",
        "        super(Linear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.W = np.random.randn(out_features, in_features)\n",
        "        self.b = np.zeros((out_features, 1))\n",
        "\n",
        "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
        "        Z1 = self.W.dot(input) + self.b\n",
        "        return Z1\n",
        "        # <<<<<<<<<\n",
        "\n",
        "    def backward(self, dz):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "vFs7QqboE3yD"
      },
      "source": [
        "## Activations\n",
        "\n",
        "The definitions for Sigmoid, Tanh, ReLU, and LeakyReLU activation functions with forward and backward pass.\n",
        "Implement the forward pass. (for now, you leave the backward pass on `pass`)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "qJAgm0GLE3yD"
      },
      "outputs": [],
      "source": [
        "#------------------------------------------------------------------------------\n",
        "#   SigmoidActivationFunction class\n",
        "#------------------------------------------------------------------------------\n",
        "class Sigmoid(Module):\n",
        "    def __init__(self):\n",
        "        super(Sigmoid, self).__init__()\n",
        "\n",
        "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
        "\n",
        "        return (1/(1 + np.exp(- input)))\n",
        "        # <<<<<<<<<\n",
        "\n",
        "    def backward(self, da):\n",
        "        pass\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "#   HyperbolicTangentActivationFunction class\n",
        "#------------------------------------------------------------------------------\n",
        "class Tanh(Module):\n",
        "    def __init__(self):\n",
        "        super(Tanh, self).__init__()\n",
        "\n",
        "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
        "\n",
        "        return (np.exp(input) - np.exp(- input))/(np.exp(input) + np.exp(- input))\n",
        "\n",
        "        # <<<<<<<<<\n",
        "\n",
        "    def backward(self, da):\n",
        "        pass\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "#   RELUActivationFunction class\n",
        "#------------------------------------------------------------------------------\n",
        "class ReLU(Module):\n",
        "    def __init__(self):\n",
        "        super(ReLU, self).__init__()\n",
        "\n",
        "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
        "\n",
        "        return np.maximum(0, input)\n",
        "        # <<<<<<<<<\n",
        "\n",
        "    def backward(self, da):\n",
        "        pass\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "#   LeakyRELUActivationFunction class\n",
        "#------------------------------------------------------------------------------\n",
        "class LeakyReLU(Module):\n",
        "    # >>>>>>>>> add something here\n",
        "    def __init__(self, alpha = 0.01):\n",
        "        self.alpha = alpha\n",
        "        super(LeakyReLU, self).__init__()\n",
        "\n",
        "    def forward(self, input: np.ndarray) -> np.ndarray:\n",
        "\n",
        "        return np.maximum(self.alpha*input, input)\n",
        "    # <<<<<<<<<<<\n",
        "    def backward(self, da):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "egWnwk0CE3yD"
      },
      "source": [
        "### Plotting the functions\n",
        "Verify your implementations of Activation functions - do your graphs look like they should?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "id": "w25SbP-QE3yD",
        "outputId": "24168e88-38f3-4a10-8bb3-46992939abf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"b29080e8-ac10-435d-b1da-ec57f5aeea05\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"b29080e8-ac10-435d-b1da-ec57f5aeea05\")) {                    Plotly.newPlot(                        \"b29080e8-ac10-435d-b1da-ec57f5aeea05\",                        [{\"name\":\"Sigmoid\",\"x\":[-4.0,-3.919191919191919,-3.8383838383838382,-3.757575757575758,-3.676767676767677,-3.595959595959596,-3.515151515151515,-3.4343434343434343,-3.3535353535353534,-3.2727272727272725,-3.191919191919192,-3.111111111111111,-3.0303030303030303,-2.9494949494949494,-2.8686868686868685,-2.787878787878788,-2.7070707070707067,-2.6262626262626263,-2.5454545454545454,-2.4646464646464645,-2.3838383838383836,-2.3030303030303028,-2.2222222222222223,-2.141414141414141,-2.0606060606060606,-1.9797979797979797,-1.8989898989898988,-1.818181818181818,-1.737373737373737,-1.6565656565656566,-1.5757575757575757,-1.4949494949494948,-1.414141414141414,-1.333333333333333,-1.2525252525252522,-1.1717171717171713,-1.0909090909090908,-1.01010101010101,-0.9292929292929291,-0.8484848484848482,-0.7676767676767673,-0.6868686868686864,-0.606060606060606,-0.5252525252525251,-0.4444444444444442,-0.3636363636363633,-0.28282828282828243,-0.20202020202020154,-0.1212121212121211,-0.04040404040404022,0.040404040404040664,0.12121212121212199,0.20202020202020243,0.2828282828282829,0.3636363636363642,0.44444444444444464,0.525252525252526,0.6060606060606064,0.6868686868686869,0.7676767676767682,0.8484848484848486,0.92929292929293,1.0101010101010104,1.0909090909090917,1.1717171717171722,1.2525252525252526,1.333333333333334,1.4141414141414144,1.4949494949494957,1.5757575757575761,1.6565656565656575,1.737373737373738,1.8181818181818183,1.8989898989898997,1.9797979797979801,2.0606060606060614,2.141414141414142,2.2222222222222223,2.3030303030303036,2.383838383838384,2.4646464646464654,2.545454545454546,2.626262626262627,2.7070707070707076,2.787878787878788,2.8686868686868694,2.94949494949495,3.030303030303031,3.1111111111111116,3.191919191919193,3.2727272727272734,3.353535353535354,3.434343434343435,3.5151515151515156,3.595959595959597,3.6767676767676774,3.757575757575758,3.838383838383839,3.9191919191919196,4.0],\"y\":[0.01798620996209156,0.01947050597740026,0.021074663483429394,0.022807911818687677,0.02468011425213936,0.02670179831666652,0.02888418518157077,0.031239217498255256,0.033779585052199225,0.03651874744261101,0.039470952888897966,0.042651252130942854,0.04607550624931942,0.04976038708393503,0.053723368777965186,0.057982708822235905,0.06255741682857327,0.06746720912569881,0.07273244715626792,0.0783740575686634,0.08441343185407771,0.09087230339198726,0.09777259985079931,0.10513626906206397,0.11298507676386015,0.12134037500947477,0.1302228405778755,0.13965218341676014,0.14964682600680101,0.16022355556030754,0.17139715215334342,0.1831799972206518,0.19558166828746196,0.20860852732604498,0.22226331164613858,0.23654473767922735,0.2514471293046626,0.2669600833870328,0.2830681858395916,0.2997507916902141,0.3169818822075857,0.334730011070984,0.35295834979419594,0.37162484014211505,0.39068245815643937,0.4100795907374461,0.4297605216677122,0.449666019712998,0.46973401723175856,0.4899003638215689,0.5100996361784312,0.5302659827682417,0.5503339802870021,0.5702394783322879,0.5899204092625541,0.6093175418435607,0.6283751598578852,0.6470416502058042,0.6652699889290161,0.6830181177924144,0.7002492083097859,0.7169318141604085,0.7330399166129673,0.7485528706953376,0.7634552623207728,0.7777366883538616,0.791391472673955,0.8044183317125382,0.8168200027793484,0.8286028478466566,0.8397764444396925,0.850353173993199,0.86034781658324,0.8697771594221246,0.8786596249905253,0.88701492323614,0.8948637309379361,0.9022274001492008,0.9091276966080128,0.9155865681459223,0.9216259424313368,0.9272675528437321,0.9325327908743012,0.9374425831714268,0.9420172911777641,0.9462766312220349,0.950239612916065,0.9539244937506807,0.9573487478690571,0.9605290471111022,0.9634812525573891,0.9662204149478009,0.9687607825017447,0.9711158148184292,0.9732982016833336,0.9753198857478605,0.9771920881813124,0.9789253365165708,0.9805294940225998,0.9820137900379085],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y\"},{\"name\":\"Tanh\",\"x\":[-4.0,-3.919191919191919,-3.8383838383838382,-3.757575757575758,-3.676767676767677,-3.595959595959596,-3.515151515151515,-3.4343434343434343,-3.3535353535353534,-3.2727272727272725,-3.191919191919192,-3.111111111111111,-3.0303030303030303,-2.9494949494949494,-2.8686868686868685,-2.787878787878788,-2.7070707070707067,-2.6262626262626263,-2.5454545454545454,-2.4646464646464645,-2.3838383838383836,-2.3030303030303028,-2.2222222222222223,-2.141414141414141,-2.0606060606060606,-1.9797979797979797,-1.8989898989898988,-1.818181818181818,-1.737373737373737,-1.6565656565656566,-1.5757575757575757,-1.4949494949494948,-1.414141414141414,-1.333333333333333,-1.2525252525252522,-1.1717171717171713,-1.0909090909090908,-1.01010101010101,-0.9292929292929291,-0.8484848484848482,-0.7676767676767673,-0.6868686868686864,-0.606060606060606,-0.5252525252525251,-0.4444444444444442,-0.3636363636363633,-0.28282828282828243,-0.20202020202020154,-0.1212121212121211,-0.04040404040404022,0.040404040404040664,0.12121212121212199,0.20202020202020243,0.2828282828282829,0.3636363636363642,0.44444444444444464,0.525252525252526,0.6060606060606064,0.6868686868686869,0.7676767676767682,0.8484848484848486,0.92929292929293,1.0101010101010104,1.0909090909090917,1.1717171717171722,1.2525252525252526,1.333333333333334,1.4141414141414144,1.4949494949494957,1.5757575757575761,1.6565656565656575,1.737373737373738,1.8181818181818183,1.8989898989898997,1.9797979797979801,2.0606060606060614,2.141414141414142,2.2222222222222223,2.3030303030303036,2.383838383838384,2.4646464646464654,2.545454545454546,2.626262626262627,2.7070707070707076,2.787878787878788,2.8686868686868694,2.94949494949495,3.030303030303031,3.1111111111111116,3.191919191919193,3.2727272727272734,3.353535353535354,3.434343434343435,3.5151515151515156,3.595959595959597,3.6767676767676774,3.757575757575758,3.838383838383839,3.9191919191919196,4.0],\"y\":[-0.9993292997390669,-0.9992116992558407,-0.9990734882770754,-0.9989110582803027,-0.9987201703458924,-0.9984958455584596,-0.9982322365559255,-0.9979224770606347,-0.9975585057250774,-0.9971308600549862,-0.9966284355304149,-0.9960382043284042,-0.995344887259809,-0.9945305716737768,-0.9935742671700297,-0.9924513900167604,-0.9911331662423851,-0.9895859425175134,-0.9877703932665305,-0.9856406120871879,-0.983143075711653,-0.9802154696913883,-0.9767853671093907,-0.9727687554219788,-0.968068412669022,-0.9625721436092375,-0.9561508998804992,-0.9486568273003458,-0.9399213093196865,-0.9297531098960385,-0.9179367629904907,-0.9042314103391286,-0.888370353849221,-0.8700616617426719,-0.8489902431682532,-0.8248218747317926,-0.7972097086650384,-0.7658037936565179,-0.7302640663818245,-0.6902770907774043,-0.6455765009944054,-0.5959666229157882,-0.5413481157551436,-0.4817437418950913,-0.41732165005887095,-0.34841301253861184,-0.2755206950101769,-0.1993160447197776,-0.1206219578831561,-0.04038206840161543,0.04038206840161587,0.12062195788315692,0.19931604471977837,0.2755206950101773,0.3484130125386125,0.4173216500588713,0.48174374189509184,0.5413481157551439,0.5959666229157886,0.645576500994406,0.6902770907774044,0.730264066381825,0.765803793656518,0.7972097086650388,0.8248218747317927,0.8489902431682533,0.870061661742672,0.8883703538492211,0.9042314103391287,0.9179367629904907,0.9297531098960387,0.9399213093196866,0.9486568273003458,0.9561508998804993,0.9625721436092376,0.9680684126690221,0.9727687554219788,0.9767853671093907,0.9802154696913883,0.983143075711653,0.9856406120871879,0.9877703932665306,0.9895859425175134,0.9911331662423851,0.9924513900167604,0.9935742671700297,0.9945305716737768,0.995344887259809,0.9960382043284042,0.9966284355304149,0.9971308600549862,0.9975585057250774,0.9979224770606347,0.9982322365559255,0.9984958455584596,0.9987201703458924,0.9989110582803027,0.9990734882770754,0.9992116992558407,0.9993292997390669],\"type\":\"scatter\",\"xaxis\":\"x2\",\"yaxis\":\"y2\"},{\"name\":\"ReLU\",\"x\":[-4.0,-3.919191919191919,-3.8383838383838382,-3.757575757575758,-3.676767676767677,-3.595959595959596,-3.515151515151515,-3.4343434343434343,-3.3535353535353534,-3.2727272727272725,-3.191919191919192,-3.111111111111111,-3.0303030303030303,-2.9494949494949494,-2.8686868686868685,-2.787878787878788,-2.7070707070707067,-2.6262626262626263,-2.5454545454545454,-2.4646464646464645,-2.3838383838383836,-2.3030303030303028,-2.2222222222222223,-2.141414141414141,-2.0606060606060606,-1.9797979797979797,-1.8989898989898988,-1.818181818181818,-1.737373737373737,-1.6565656565656566,-1.5757575757575757,-1.4949494949494948,-1.414141414141414,-1.333333333333333,-1.2525252525252522,-1.1717171717171713,-1.0909090909090908,-1.01010101010101,-0.9292929292929291,-0.8484848484848482,-0.7676767676767673,-0.6868686868686864,-0.606060606060606,-0.5252525252525251,-0.4444444444444442,-0.3636363636363633,-0.28282828282828243,-0.20202020202020154,-0.1212121212121211,-0.04040404040404022,0.040404040404040664,0.12121212121212199,0.20202020202020243,0.2828282828282829,0.3636363636363642,0.44444444444444464,0.525252525252526,0.6060606060606064,0.6868686868686869,0.7676767676767682,0.8484848484848486,0.92929292929293,1.0101010101010104,1.0909090909090917,1.1717171717171722,1.2525252525252526,1.333333333333334,1.4141414141414144,1.4949494949494957,1.5757575757575761,1.6565656565656575,1.737373737373738,1.8181818181818183,1.8989898989898997,1.9797979797979801,2.0606060606060614,2.141414141414142,2.2222222222222223,2.3030303030303036,2.383838383838384,2.4646464646464654,2.545454545454546,2.626262626262627,2.7070707070707076,2.787878787878788,2.8686868686868694,2.94949494949495,3.030303030303031,3.1111111111111116,3.191919191919193,3.2727272727272734,3.353535353535354,3.434343434343435,3.5151515151515156,3.595959595959597,3.6767676767676774,3.757575757575758,3.838383838383839,3.9191919191919196,4.0],\"y\":[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.040404040404040664,0.12121212121212199,0.20202020202020243,0.2828282828282829,0.3636363636363642,0.44444444444444464,0.525252525252526,0.6060606060606064,0.6868686868686869,0.7676767676767682,0.8484848484848486,0.92929292929293,1.0101010101010104,1.0909090909090917,1.1717171717171722,1.2525252525252526,1.333333333333334,1.4141414141414144,1.4949494949494957,1.5757575757575761,1.6565656565656575,1.737373737373738,1.8181818181818183,1.8989898989898997,1.9797979797979801,2.0606060606060614,2.141414141414142,2.2222222222222223,2.3030303030303036,2.383838383838384,2.4646464646464654,2.545454545454546,2.626262626262627,2.7070707070707076,2.787878787878788,2.8686868686868694,2.94949494949495,3.030303030303031,3.1111111111111116,3.191919191919193,3.2727272727272734,3.353535353535354,3.434343434343435,3.5151515151515156,3.595959595959597,3.6767676767676774,3.757575757575758,3.838383838383839,3.9191919191919196,4.0],\"type\":\"scatter\",\"xaxis\":\"x3\",\"yaxis\":\"y3\"},{\"name\":\"LeakyReLU\",\"x\":[-4.0,-3.919191919191919,-3.8383838383838382,-3.757575757575758,-3.676767676767677,-3.595959595959596,-3.515151515151515,-3.4343434343434343,-3.3535353535353534,-3.2727272727272725,-3.191919191919192,-3.111111111111111,-3.0303030303030303,-2.9494949494949494,-2.8686868686868685,-2.787878787878788,-2.7070707070707067,-2.6262626262626263,-2.5454545454545454,-2.4646464646464645,-2.3838383838383836,-2.3030303030303028,-2.2222222222222223,-2.141414141414141,-2.0606060606060606,-1.9797979797979797,-1.8989898989898988,-1.818181818181818,-1.737373737373737,-1.6565656565656566,-1.5757575757575757,-1.4949494949494948,-1.414141414141414,-1.333333333333333,-1.2525252525252522,-1.1717171717171713,-1.0909090909090908,-1.01010101010101,-0.9292929292929291,-0.8484848484848482,-0.7676767676767673,-0.6868686868686864,-0.606060606060606,-0.5252525252525251,-0.4444444444444442,-0.3636363636363633,-0.28282828282828243,-0.20202020202020154,-0.1212121212121211,-0.04040404040404022,0.040404040404040664,0.12121212121212199,0.20202020202020243,0.2828282828282829,0.3636363636363642,0.44444444444444464,0.525252525252526,0.6060606060606064,0.6868686868686869,0.7676767676767682,0.8484848484848486,0.92929292929293,1.0101010101010104,1.0909090909090917,1.1717171717171722,1.2525252525252526,1.333333333333334,1.4141414141414144,1.4949494949494957,1.5757575757575761,1.6565656565656575,1.737373737373738,1.8181818181818183,1.8989898989898997,1.9797979797979801,2.0606060606060614,2.141414141414142,2.2222222222222223,2.3030303030303036,2.383838383838384,2.4646464646464654,2.545454545454546,2.626262626262627,2.7070707070707076,2.787878787878788,2.8686868686868694,2.94949494949495,3.030303030303031,3.1111111111111116,3.191919191919193,3.2727272727272734,3.353535353535354,3.434343434343435,3.5151515151515156,3.595959595959597,3.6767676767676774,3.757575757575758,3.838383838383839,3.9191919191919196,4.0],\"y\":[-0.04,-0.039191919191919194,-0.03838383838383838,-0.03757575757575758,-0.03676767676767677,-0.03595959595959596,-0.03515151515151515,-0.03434343434343434,-0.033535353535353536,-0.03272727272727272,-0.031919191919191924,-0.031111111111111114,-0.030303030303030304,-0.029494949494949494,-0.028686868686868684,-0.02787878787878788,-0.027070707070707068,-0.026262626262626265,-0.025454545454545455,-0.024646464646464646,-0.023838383838383836,-0.02303030303030303,-0.022222222222222223,-0.02141414141414141,-0.020606060606060607,-0.019797979797979797,-0.018989898989898987,-0.01818181818181818,-0.01737373737373737,-0.016565656565656565,-0.01575757575757576,-0.014949494949494949,-0.014141414141414139,-0.01333333333333333,-0.012525252525252523,-0.011717171717171713,-0.010909090909090908,-0.0101010101010101,-0.00929292929292929,-0.008484848484848482,-0.007676767676767673,-0.006868686868686864,-0.00606060606060606,-0.005252525252525251,-0.004444444444444442,-0.0036363636363636333,-0.0028282828282828244,-0.0020202020202020154,-0.001212121212121211,-0.0004040404040404022,0.040404040404040664,0.12121212121212199,0.20202020202020243,0.2828282828282829,0.3636363636363642,0.44444444444444464,0.525252525252526,0.6060606060606064,0.6868686868686869,0.7676767676767682,0.8484848484848486,0.92929292929293,1.0101010101010104,1.0909090909090917,1.1717171717171722,1.2525252525252526,1.333333333333334,1.4141414141414144,1.4949494949494957,1.5757575757575761,1.6565656565656575,1.737373737373738,1.8181818181818183,1.8989898989898997,1.9797979797979801,2.0606060606060614,2.141414141414142,2.2222222222222223,2.3030303030303036,2.383838383838384,2.4646464646464654,2.545454545454546,2.626262626262627,2.7070707070707076,2.787878787878788,2.8686868686868694,2.94949494949495,3.030303030303031,3.1111111111111116,3.191919191919193,3.2727272727272734,3.353535353535354,3.434343434343435,3.5151515151515156,3.595959595959597,3.6767676767676774,3.757575757575758,3.838383838383839,3.9191919191919196,4.0],\"type\":\"scatter\",\"xaxis\":\"x4\",\"yaxis\":\"y4\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.45]},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.575,1.0]},\"xaxis2\":{\"anchor\":\"y2\",\"domain\":[0.55,1.0]},\"yaxis2\":{\"anchor\":\"x2\",\"domain\":[0.575,1.0]},\"xaxis3\":{\"anchor\":\"y3\",\"domain\":[0.0,0.45]},\"yaxis3\":{\"anchor\":\"x3\",\"domain\":[0.0,0.425]},\"xaxis4\":{\"anchor\":\"y4\",\"domain\":[0.55,1.0]},\"yaxis4\":{\"anchor\":\"x4\",\"domain\":[0.0,0.425]},\"title\":{\"text\":\"Activation functions\"},\"height\":600,\"width\":800},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('b29080e8-ac10-435d-b1da-ec57f5aeea05');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "activationsInput = np.linspace(-4,4,100)\n",
        "\n",
        "sigmoid = Sigmoid()\n",
        "y = sigmoid.forward(activationsInput)\n",
        "\n",
        "fig = make_subplots(rows=2, cols=2)\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=activationsInput, y=y, name='Sigmoid'),\n",
        "    row=1, col=1\n",
        ")\n",
        "\n",
        "tanh = Tanh()\n",
        "y = tanh.forward(activationsInput)\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=activationsInput, y=y, name='Tanh'),\n",
        "    row=1, col=2\n",
        ")\n",
        "\n",
        "relu = ReLU()\n",
        "y = relu(activationsInput)\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=activationsInput, y=y, name='ReLU'),\n",
        "    row=2, col=1\n",
        ")\n",
        "\n",
        "leakyrelu = LeakyReLU()\n",
        "y = leakyrelu(activationsInput)\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=activationsInput, y=y, name='LeakyReLU'),\n",
        "    row=2, col=2\n",
        ")\n",
        "\n",
        "fig.update_layout(height=600, width=800, title_text=\"Activation functions\")\n",
        "fig.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "hgw2LwyIE3yE"
      },
      "source": [
        "### Perceptron feed forward\n",
        "\n",
        "Model your Perceptron.\n",
        "Define and initialize perceptron with \"1 neuron\"!\n",
        "Feed `xInput1` and `xInput2` to the perceptron and print the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "KNwAUfqSE3yE"
      },
      "outputs": [],
      "source": [
        "# xInput1 is just a single sample - it contains 1 sample with 10 features\n",
        "xInput1 = np.expand_dims(np.arange(10), axis=1)     # shape <10; 1>\n",
        "\n",
        "# xInput2 is just a mini-batch! - it contains 4 samples with 10 features\n",
        "xInput2 = np.random.randn(10, 4)                    # shape <10; 4>\n",
        "\n",
        "# >>>>>>>>> Initialize Your Perceptron Here\n",
        "in_features = 10\n",
        "out_features = 5\n",
        "\n",
        "perceptron = Linear(in_features,out_features)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "jk18DuU8E3yE"
      },
      "source": [
        "Your Perceptron with an Activation function.\n",
        "Use previously defined perceptron and use its output as input for the activation function sigmoid and LeakyReLU.\n",
        "Feed `xInput1` and `xInput2` to the perceptron, print and observe the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "id": "irsga9YCE3yE",
        "outputId": "e9c28c92-cbdf-45d8-e518-51f3e8f27eda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Perceptron output for single sample:\n",
            " [[-0.64148785]\n",
            " [23.27585508]\n",
            " [17.06314461]\n",
            " [ 4.6571887 ]\n",
            " [ 5.75720582]]\n",
            "Sigmoid output for single sample:\n",
            " [[0.34491029]\n",
            " [1.        ]\n",
            " [0.99999996]\n",
            " [0.99059616]\n",
            " [0.99685003]]\n",
            "LeakyReLU output for single sample:\n",
            " [[-6.41487845e-03]\n",
            " [ 2.32758551e+01]\n",
            " [ 1.70631446e+01]\n",
            " [ 4.65718870e+00]\n",
            " [ 5.75720582e+00]]\n",
            "\n",
            "Perceptron output for mini-batch:\n",
            " [[ 2.07059489 -0.15466929  1.35540997  1.31892875]\n",
            " [ 0.78890301 -1.27644715  2.65854787 -0.353657  ]\n",
            " [-3.65849429 -0.20248161 -0.24683223 -1.69723694]\n",
            " [ 3.64677367 -0.23259072  0.16178315 -1.67532563]\n",
            " [ 1.07740065  0.06345024  1.08517418  0.68462678]]\n",
            "Sigmoid output for mini-batch:\n",
            " [[0.88801214 0.46140958 0.79501268 0.78900342]\n",
            " [0.68759574 0.2181556  0.93453588 0.41249589]\n",
            " [0.02512381 0.44955184 0.43860335 0.15482648]\n",
            " [0.97458751 0.44211305 0.5403578  0.15771543]\n",
            " [0.74600177 0.51585724 0.7474719  0.66477056]]\n",
            "LeakyReLU output for mini-batch:\n",
            " [[ 2.07059489e+00 -1.54669289e-03  1.35540997e+00  1.31892875e+00]\n",
            " [ 7.88903013e-01 -1.27644715e-02  2.65854787e+00 -3.53657000e-03]\n",
            " [-3.65849429e-02 -2.02481608e-03 -2.46832231e-03 -1.69723694e-02]\n",
            " [ 3.64677367e+00 -2.32590715e-03  1.61783147e-01 -1.67532563e-02]\n",
            " [ 1.07740065e+00  6.34502409e-02  1.08517418e+00  6.84626778e-01]]\n"
          ]
        }
      ],
      "source": [
        "# >>>>>>>>> Initialize activations and feed them after perceptron\n",
        "\n",
        "output1 = perceptron.forward(xInput1)\n",
        "output2 = perceptron.forward(xInput2)\n",
        "\n",
        "\n",
        "sigmoid_output1 = sigmoid(output1)\n",
        "sigmoid_output2 = sigmoid(output2)\n",
        "\n",
        "leaky_relu_output1 = leakyrelu(output1)\n",
        "leaky_relu_output2 = leakyrelu(output2)\n",
        "print(\"Perceptron output for single sample:\\n\", output1)\n",
        "print(\"Sigmoid output for single sample:\\n\", sigmoid_output1)\n",
        "print(\"LeakyReLU output for single sample:\\n\", leaky_relu_output1)\n",
        "\n",
        "print(\"\\nPerceptron output for mini-batch:\\n\", output2)\n",
        "print(\"Sigmoid output for mini-batch:\\n\", sigmoid_output2)\n",
        "print(\"LeakyReLU output for mini-batch:\\n\", leaky_relu_output2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "0R-_zWbmE3yE"
      },
      "source": [
        "## Task 1b:\n",
        "\n",
        "Finish the implementation of class `Model` - finish the call of forward feed.\n",
        "Declare a simple model consisting of:\n",
        " 1. Input Layer\n",
        " 2. 3 Linear Layers with arbitrary number of neurons\n",
        " 3. Output Linear Layer with 1 neuron.\n",
        "\n",
        "...and activation functions to add non-linearity\n",
        "\n",
        "Declare your own input vector with 16 features.\n",
        "Perform forward pass through the network and print the results.\n",
        "\n",
        "### Model class\n",
        "\n",
        "Implementation of the **`Model`** class.\n",
        "Define its forward function - the implementation of forward and backward pass is sensitive to the order of called operations.\n",
        "Each Layer(module) of type **`Module`** can be saved to the attribute **`Module.modules`** using the **`add_module`** method.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Ry-_iGv4E3yE"
      },
      "outputs": [],
      "source": [
        "#------------------------------------------------------------------------------\n",
        "#   Model class\n",
        "#------------------------------------------------------------------------------\n",
        "class Model(Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.add_module(Linear(16, 32) , \"linearInput\")  # Input -> 32 neurons\n",
        "        self.add_module(Linear(32, 48) , \"linear1\" )  # Input -> 32 neurons\n",
        "        self.add_module(Linear(48, 64) , \"linear2\")  # 32 -> 64 neurons\n",
        "        self.add_module(Linear(64, 32) , \"linear3\")  # 64 -> 32 neurons\n",
        "        self.add_module(Linear(32, 1)  , \"linear_out\")  # 32 -> 1 neuron (output)\n",
        "\n",
        "    def forward(self, input):\n",
        "        # Funkcion and function order matter, tried manny alternatives dn which one is better or it it matters in this low-lvl case\n",
        "        x = self.modules[\"linearInput\"].forward(input)\n",
        "        x = sigmoid(x)\n",
        "        #x = leakyrelu(x)\n",
        "        x = self.modules[\"linear1\"].forward(x)\n",
        "        #x = relu(x)\n",
        "        x = sigmoid(x)\n",
        "        x = self.modules[\"linear2\"].forward(x)\n",
        "        #x = relu(x)\n",
        "        x = sigmoid(x)\n",
        "        x = self.modules[\"linear3\"].forward(x)\n",
        "        #x = relu(x)\n",
        "        x = sigmoid(x)\n",
        "        x = self.modules[\"linear_out\"].forward(x)\n",
        "        x = sigmoid(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def backward(self, dA: np.ndarray):\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "sW6WNenwE3yE",
        "outputId": "d4d42fa6-a910-42ac-f7af-9e43bf8ec78e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_input:\n",
            " (16, 16)\n",
            "xInput1:\n",
            " (16, 1)\n",
            "xInput2:\n",
            " (16, 4)\n"
          ]
        }
      ],
      "source": [
        "model = Model()\n",
        "# We were told to have 3 layers.... not sure if input and output are counted so i make it  -> 1 + 3 + 1 <-\n",
        "# >>>>>>>>> Build the model architecture with 2 hidden layers and one final output layer that can process - feed forward the xInput1 and xInput2\n",
        "# we are told to feed it with xInput1 and xInput2 but those have 10 \"features \" tho we need 16 so i make a new one for this ,\n",
        "\n",
        "\n",
        "x_input = np.random.randn(16, 16)\n",
        "xInput1 = np.expand_dims(np.arange(16), axis=1)\n",
        "xInput2 = np.random.randn(16, 4)\n",
        "\n",
        "print(\"x_input:\\n\", x_input.shape)\n",
        "print(\"xInput1:\\n\", xInput1.shape)\n",
        "print(\"xInput2:\\n\", xInput2.shape)\n",
        "\n",
        "\n",
        "\n",
        "output = model.forward(x_input)\n",
        "output1 = model.forward(xInput1)\n",
        "output2 = model.forward(xInput2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "pycharm": {
          "is_executing": true,
          "name": "#%%\n"
        },
        "id": "9Rg9tKX1E3yE",
        "outputId": "9e8cc83a-14d5-422f-96ba-e18d4514c392",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model output:\n",
            " (1, 16)\n",
            "Model output:\n",
            " (1, 1)\n",
            "Model output:\n",
            " (1, 4)\n"
          ]
        }
      ],
      "source": [
        "# What are the output shapes after feeding xInput1 and xInput2 to the model ?\n",
        "# How many samples do they contain ? they contain 16,1 and 4 samples. Based on how much samples they already had.. only features vere reduced.\n",
        "\n",
        "\n",
        "print(\"Model output:\\n\", output.shape)\n",
        "print(\"Model output:\\n\", output1.shape)\n",
        "print(\"Model output:\\n\", output2.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "mgsOs4RDE3yE"
      },
      "outputs": [],
      "source": [
        "# Monkey dolls !"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "history_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}